{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 3: NB_multinomial with word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucas Tay\\OneDrive - AIA Singapore Private Limited (1)\\Desktop\\AI project\\WELFake_AI_Project\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import base64\n",
    "import struct\n",
    "import warnings\n",
    "import torch\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: False\n"
     ]
    }
   ],
   "source": [
    "# Define device for torch\n",
    "use_cuda = True\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "EMBEDDING_COLUMN_NAMES = [\"tfidf_embedding\",\"bow_embedding\",\"w2v_embedding\", \"roberta_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode the custom embedding format\n",
    "def decode_embedding(encoded_str):\n",
    "    \"\"\"\n",
    "    Decode the custom embedding format to a numeric vector.\n",
    "    Example input: 'AQAAAAAAAABAAAAAAAAAAQAAAAAAAAEAAAAAAAAAAQA...'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First try base64 decoding\n",
    "        try:\n",
    "            # Try standard base64\n",
    "            decoded = base64.b64decode(encoded_str)\n",
    "        except:\n",
    "            # If that fails, try to pad the string and decode\n",
    "            padding_needed = len(encoded_str) % 4\n",
    "            if padding_needed:\n",
    "                encoded_str += '=' * (4 - padding_needed)\n",
    "            decoded = base64.b64decode(encoded_str)\n",
    "        \n",
    "        # Try to interpret as floats (8 bytes per float)\n",
    "        if len(decoded) % 8 == 0:\n",
    "            num_floats = len(decoded) // 8\n",
    "            return np.array(struct.unpack(f'>{num_floats}d', decoded))\n",
    "        \n",
    "        # Try to interpret as floats (4 bytes per float)\n",
    "        if len(decoded) % 4 == 0:\n",
    "            num_floats = len(decoded) // 4\n",
    "            return np.array(struct.unpack(f'>{num_floats}f', decoded))\n",
    "            \n",
    "        # If the above fail, try to interpret as a sequence of bytes\n",
    "        return np.frombuffer(decoded, dtype=np.uint8)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding embedding: {e}\")\n",
    "        # As a fallback, convert each character to its ASCII value\n",
    "        return np.array([ord(c) for c in encoded_str])\n",
    "\n",
    "def process_embedding(train_df, test_df, embedding_name):\n",
    "    \"\"\"\n",
    "    Process a specific embedding type from the datasets.\n",
    "    Returns processed X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"PROCESSING {embedding_name} EMBEDDING\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Check if embedding exists in both datasets\n",
    "    if embedding_name not in train_df.columns or embedding_name not in test_df.columns:\n",
    "        print(f\"Warning: {embedding_name} not found in both datasets!\")\n",
    "        print(f\"Train columns: {train_df.columns}\")\n",
    "        print(f\"Test columns: {test_df.columns}\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    print(f\"\\nExtracting {embedding_name} embeddings...\")\n",
    "    \n",
    "    # Sample an embedding to understand its format\n",
    "    sample_embedding_train = train_df[embedding_name].iloc[0]\n",
    "    print(f\"Sample training embedding type: {type(sample_embedding_train)}\")\n",
    "    \n",
    "    # Process training embeddings\n",
    "    if isinstance(sample_embedding_train, list):\n",
    "        print(f\"Training embedding appears to be a list with {len(sample_embedding_train)} items\")\n",
    "        X_train = np.array(train_df[embedding_name].tolist())\n",
    "    elif isinstance(sample_embedding_train, str):\n",
    "        print(\"Training embedding appears to be a string, will decode each embedding\")\n",
    "        X_train = np.array([decode_embedding(emb) for emb in train_df[embedding_name]])\n",
    "    else:\n",
    "        print(f\"Unknown training embedding format, will try to convert\")\n",
    "        X_train = np.array([np.array(emb) for emb in train_df[embedding_name]])\n",
    "    \n",
    "    # Sample an embedding from test set\n",
    "    sample_embedding_test = test_df[embedding_name].iloc[0]\n",
    "    print(f\"Sample test embedding type: {type(sample_embedding_test)}\")\n",
    "    \n",
    "    # Process test embeddings\n",
    "    if isinstance(sample_embedding_test, list):\n",
    "        print(f\"Test embedding appears to be a list with {len(sample_embedding_test)} items\")\n",
    "        X_test = np.array(test_df[embedding_name].tolist())\n",
    "    elif isinstance(sample_embedding_test, str):\n",
    "        print(\"Test embedding appears to be a string, will decode each embedding\")\n",
    "        X_test = np.array([decode_embedding(emb) for emb in test_df[embedding_name]])\n",
    "    else:\n",
    "        print(f\"Unknown test embedding format, will try to convert\")\n",
    "        X_test = np.array([np.array(emb) for emb in test_df[embedding_name]])\n",
    "    \n",
    "    # Extract labels\n",
    "    y_train = np.array(train_df['label'])\n",
    "    y_test = np.array(test_df['label'])\n",
    "    \n",
    "    print(f\"Prepared training features with shape {X_train.shape} and labels with shape {y_train.shape}\")\n",
    "    print(f\"Prepared testing features with shape {X_test.shape} and labels with shape {y_test.shape}\")\n",
    "    \n",
    "    # Check if dimensions match\n",
    "    if X_train.shape[1] != X_test.shape[1]:\n",
    "        print(f\"WARNING: Feature dimensions don't match! Training: {X_train.shape[1]}, Testing: {X_test.shape[1]}\")\n",
    "        print(\"Cannot proceed with this embedding type.\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, embedding_name):\n",
    "    \"\"\"Train and evaluate the NB model on the given embedding\"\"\"\n",
    "    try:\n",
    "        print(\"\\nScaling features...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        print(\"Features scaled successfully\")\n",
    "        \n",
    "        # Remove NaN values\n",
    "        X_train_scaled = np.nan_to_num(X_train_scaled, nan=0.0)\n",
    "        X_test_scaled = np.nan_to_num(X_test_scaled, nan=0.0)\n",
    "        \n",
    "        print(\"\\nPerforming hyperparameter optimization...\")\n",
    "        param_grid = {'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]}\n",
    "        grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
    "        \n",
    "        print(\"Fitting grid search...\")\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_score = grid_search.best_score_\n",
    "        print(f\"Best alpha parameter: {best_alpha}\")\n",
    "        print(f\"Best cross-validation score: {best_score:.4f}\")\n",
    "        \n",
    "        print(\"\\nPerforming k-fold cross-validation with best alpha...\")\n",
    "        k_folds = 5\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        nb_cv = MultinomialNB(alpha=best_alpha)\n",
    "        cv_scores = cross_val_score(nb_cv, X_train_scaled, y_train, cv=kf, scoring='accuracy')\n",
    "        print(f\"CV Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "        print(f\"Individual fold scores: {cv_scores}\")\n",
    "        \n",
    "        print(\"\\nTraining the final model...\")\n",
    "        nb_final = MultinomialNB(alpha=best_alpha)\n",
    "        nb_final.fit(X_train_scaled, y_train)\n",
    "        print(\"Model training complete\")\n",
    "        \n",
    "        print(\"\\nEvaluating model performance on test set...\")\n",
    "        y_pred = nb_final.predict(X_test_scaled)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        class_report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(class_report)\n",
    "        \n",
    "        print(\"\\nAnalyzing feature importance...\")\n",
    "        try:\n",
    "            feature_importance = nb_final.feature_log_prob_[1] - nb_final.feature_log_prob_[0]\n",
    "            top_features_idx = np.argsort(feature_importance)[-10:]  # Get indices of top 10 most important features\n",
    "            \n",
    "            print(\"Top 10 most important features (by difference in log probability):\")\n",
    "            for i, idx in enumerate(top_features_idx[::-1], 1):\n",
    "                print(f\"{i}. Feature {idx}: {feature_importance[idx]:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not analyze feature importance: {e}\")\n",
    "        \n",
    "        # Save results\n",
    "        print(\"\\nSaving results...\")\n",
    "        results = {\n",
    "            \"model_name\": f\"MultinomialNB with {embedding_name}\",\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"best_alpha\": float(best_alpha),\n",
    "            \"best_cv_score\": float(best_score),\n",
    "            \"k_fold_cv_scores\": {\n",
    "                \"mean\": float(cv_scores.mean()),\n",
    "                \"std\": float(cv_scores.std()),\n",
    "                \"individual_folds\": cv_scores.tolist()\n",
    "            },\n",
    "            \"test_metrics\": {\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"confusion_matrix\": conf_matrix.tolist(),\n",
    "                \"classification_report\": class_report_dict\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        # Ensure the results directory exists\n",
    "        if not os.path.exists('model_results'):\n",
    "            os.makedirs('model_results')\n",
    "            \n",
    "        results_filename = f\"model_results/nb_multinomial_{embedding_name}_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        try:\n",
    "            with open(results_filename, 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "            print(f\"Results saved to {results_filename}\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Could not save results to file: {e}\")\n",
    "            return results\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training/evaluation: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Load Training Dataset\n",
    "    print(\"\\nLoading training dataset...\")\n",
    "    try:\n",
    "        train_dataset = load_dataset(\"Paulozs/WELFake_embeddings\", split=\"train\")\n",
    "        train_df = pd.DataFrame(train_dataset)\n",
    "        print(f\"Training dataset loaded successfully! Shape: {train_df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading training dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Load Test Dataset\n",
    "    print(\"\\nLoading Test dataset...\")\n",
    "    try:\n",
    "        test_dataset = load_dataset(\"lelexuanzz/Gossipcop_Politifact_Test\", split=\"train\")\n",
    "        test_df = pd.DataFrame(test_dataset)\n",
    "        print(f\"Testing dataset loaded successfully! Shape: {test_df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading testing dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Summary dict to store results for all embeddings\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process each embedding type\n",
    "    for embedding_name in EMBEDDING_COLUMN_NAMES:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Process the embedding\n",
    "        X_train, X_test, y_train, y_test = process_embedding(train_df, test_df, embedding_name)\n",
    "        \n",
    "        if X_train is not None:\n",
    "            # Train and evaluate model on this embedding\n",
    "            results = train_and_evaluate_model(X_train, X_test, y_train, y_test, embedding_name)\n",
    "            \n",
    "            if results:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                results[\"processing_time\"] = elapsed_time\n",
    "                all_results[embedding_name] = results\n",
    "                print(f\"\\nCompleted processing {embedding_name} in {elapsed_time:.2f} seconds\")\n",
    "            else:\n",
    "                print(f\"\\nFailed to process {embedding_name}\")\n",
    "        else:\n",
    "            print(f\"\\nSkipping {embedding_name} due to preprocessing issues\")\n",
    "    \n",
    "    # Compare all embedding results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EMBEDDING COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if all_results:\n",
    "        print(\"\\nAccuracy comparison:\")\n",
    "        for embedding, results in all_results.items():\n",
    "            accuracy = results[\"test_metrics\"][\"accuracy\"]\n",
    "            cv_score = results[\"best_cv_score\"]\n",
    "            print(f\"{embedding}: Test Accuracy = {accuracy:.4f}, CV Score = {cv_score:.4f}\")\n",
    "        \n",
    "        # Save comparison results\n",
    "        comparison_filename = f\"model_results/embedding_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        try:\n",
    "            with open(comparison_filename, 'w') as f:\n",
    "                json.dump(all_results, f, indent=4)\n",
    "            print(f\"\\nComparison results saved to {comparison_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nCould not save comparison results to file: {e}\")\n",
    "    else:\n",
    "        print(\"No results to compare. All embedding processing failed.\")\n",
    "    \n",
    "    print(\"\\nImplementation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training dataset...\n",
      "Training dataset loaded successfully! Shape: (62592, 7)\n",
      "\n",
      "Loading Test dataset...\n",
      "Testing dataset loaded successfully! Shape: (6900, 6)\n",
      "\n",
      "==================================================\n",
      "PROCESSING tfidf_embedding EMBEDDING\n",
      "==================================================\n",
      "\n",
      "Extracting tfidf_embedding embeddings...\n",
      "Sample training embedding type: <class 'list'>\n",
      "Training embedding appears to be a list with 300 items\n",
      "Sample test embedding type: <class 'list'>\n",
      "Test embedding appears to be a list with 300 items\n",
      "Prepared training features with shape (62592, 300) and labels with shape (62592,)\n",
      "Prepared testing features with shape (6900, 300) and labels with shape (6900,)\n",
      "\n",
      "Scaling features...\n",
      "Features scaled successfully\n",
      "\n",
      "Performing hyperparameter optimization...\n",
      "Fitting grid search...\n",
      "Best alpha parameter: 0.001\n",
      "Best cross-validation score: 0.5558\n",
      "\n",
      "Performing k-fold cross-validation with best alpha...\n",
      "CV Accuracy: 0.5558 ± 0.0011\n",
      "Individual fold scores: [0.5542775  0.55571531 0.55767695 0.55591948 0.55552005]\n",
      "\n",
      "Training the final model...\n",
      "Model training complete\n",
      "\n",
      "Evaluating model performance on test set...\n",
      "Test Accuracy: 0.6620\n",
      "Confusion Matrix:\n",
      "[[4568    0]\n",
      " [2332    0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80      4568\n",
      "           1       0.00      0.00      0.00      2332\n",
      "\n",
      "    accuracy                           0.66      6900\n",
      "   macro avg       0.33      0.50      0.40      6900\n",
      "weighted avg       0.44      0.66      0.53      6900\n",
      "\n",
      "\n",
      "Analyzing feature importance...\n",
      "Top 10 most important features (by difference in log probability):\n",
      "1. Feature 1: 0.3277\n",
      "2. Feature 2: 0.2171\n",
      "3. Feature 7: 0.1244\n",
      "4. Feature 5: 0.0620\n",
      "5. Feature 9: 0.0524\n",
      "6. Feature 13: 0.0263\n",
      "7. Feature 38: 0.0259\n",
      "8. Feature 8: 0.0242\n",
      "9. Feature 118: 0.0226\n",
      "10. Feature 31: 0.0224\n",
      "\n",
      "Saving results...\n",
      "Results saved to model_results/nb_multinomial_tfidf_embedding_results_20250421_191752.json\n",
      "\n",
      "Completed processing tfidf_embedding in 7.50 seconds\n",
      "\n",
      "==================================================\n",
      "PROCESSING bow_embedding EMBEDDING\n",
      "==================================================\n",
      "\n",
      "Extracting bow_embedding embeddings...\n",
      "Sample training embedding type: <class 'list'>\n",
      "Training embedding appears to be a list with 300 items\n",
      "Sample test embedding type: <class 'list'>\n",
      "Test embedding appears to be a list with 300 items\n",
      "Prepared training features with shape (62592, 300) and labels with shape (62592,)\n",
      "Prepared testing features with shape (6900, 300) and labels with shape (6900,)\n",
      "\n",
      "Scaling features...\n",
      "Features scaled successfully\n",
      "\n",
      "Performing hyperparameter optimization...\n",
      "Fitting grid search...\n",
      "Best alpha parameter: 0.001\n",
      "Best cross-validation score: 0.5558\n",
      "\n",
      "Performing k-fold cross-validation with best alpha...\n",
      "CV Accuracy: 0.5558 ± 0.0011\n",
      "Individual fold scores: [0.5542775  0.55571531 0.55767695 0.55591948 0.55552005]\n",
      "\n",
      "Training the final model...\n",
      "Model training complete\n",
      "\n",
      "Evaluating model performance on test set...\n",
      "Test Accuracy: 0.6620\n",
      "Confusion Matrix:\n",
      "[[4568    0]\n",
      " [2332    0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80      4568\n",
      "           1       0.00      0.00      0.00      2332\n",
      "\n",
      "    accuracy                           0.66      6900\n",
      "   macro avg       0.33      0.50      0.40      6900\n",
      "weighted avg       0.44      0.66      0.53      6900\n",
      "\n",
      "\n",
      "Analyzing feature importance...\n",
      "Top 10 most important features (by difference in log probability):\n",
      "1. Feature 1: 0.0194\n",
      "2. Feature 79: 0.0174\n",
      "3. Feature 7: 0.0121\n",
      "4. Feature 155: 0.0116\n",
      "5. Feature 8: 0.0102\n",
      "6. Feature 98: 0.0095\n",
      "7. Feature 95: 0.0076\n",
      "8. Feature 59: 0.0067\n",
      "9. Feature 55: 0.0066\n",
      "10. Feature 94: 0.0063\n",
      "\n",
      "Saving results...\n",
      "Results saved to model_results/nb_multinomial_bow_embedding_results_20250421_191759.json\n",
      "\n",
      "Completed processing bow_embedding in 7.25 seconds\n",
      "\n",
      "==================================================\n",
      "PROCESSING w2v_embedding EMBEDDING\n",
      "==================================================\n",
      "\n",
      "Extracting w2v_embedding embeddings...\n",
      "Sample training embedding type: <class 'list'>\n",
      "Training embedding appears to be a list with 300 items\n",
      "Sample test embedding type: <class 'list'>\n",
      "Test embedding appears to be a list with 300 items\n",
      "Prepared training features with shape (62592, 300) and labels with shape (62592,)\n",
      "Prepared testing features with shape (6900, 300) and labels with shape (6900,)\n",
      "\n",
      "Scaling features...\n",
      "Features scaled successfully\n",
      "\n",
      "Performing hyperparameter optimization...\n",
      "Fitting grid search...\n",
      "Best alpha parameter: 0.001\n",
      "Best cross-validation score: 0.5883\n",
      "\n",
      "Performing k-fold cross-validation with best alpha...\n",
      "CV Accuracy: 0.5885 ± 0.0019\n",
      "Individual fold scores: [0.58479112 0.5889448  0.58995047 0.58899185 0.5897907 ]\n",
      "\n",
      "Training the final model...\n",
      "Model training complete\n",
      "\n",
      "Evaluating model performance on test set...\n",
      "Test Accuracy: 0.6083\n",
      "Confusion Matrix:\n",
      "[[4088  480]\n",
      " [2223  109]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      4568\n",
      "           1       0.19      0.05      0.07      2332\n",
      "\n",
      "    accuracy                           0.61      6900\n",
      "   macro avg       0.42      0.47      0.41      6900\n",
      "weighted avg       0.49      0.61      0.52      6900\n",
      "\n",
      "\n",
      "Analyzing feature importance...\n",
      "Top 10 most important features (by difference in log probability):\n",
      "1. Feature 175: 0.1330\n",
      "2. Feature 245: 0.0963\n",
      "3. Feature 247: 0.0910\n",
      "4. Feature 239: 0.0905\n",
      "5. Feature 87: 0.0835\n",
      "6. Feature 133: 0.0780\n",
      "7. Feature 31: 0.0715\n",
      "8. Feature 225: 0.0711\n",
      "9. Feature 273: 0.0689\n",
      "10. Feature 290: 0.0654\n",
      "\n",
      "Saving results...\n",
      "Results saved to model_results/nb_multinomial_w2v_embedding_results_20250421_191806.json\n",
      "\n",
      "Completed processing w2v_embedding in 7.53 seconds\n",
      "\n",
      "==================================================\n",
      "PROCESSING roberta_embedding EMBEDDING\n",
      "==================================================\n",
      "\n",
      "Extracting roberta_embedding embeddings...\n",
      "Sample training embedding type: <class 'list'>\n",
      "Training embedding appears to be a list with 300 items\n",
      "Sample test embedding type: <class 'list'>\n",
      "Test embedding appears to be a list with 300 items\n",
      "Prepared training features with shape (62592, 300) and labels with shape (62592,)\n",
      "Prepared testing features with shape (6900, 300) and labels with shape (6900,)\n",
      "\n",
      "Scaling features...\n",
      "Features scaled successfully\n",
      "\n",
      "Performing hyperparameter optimization...\n",
      "Fitting grid search...\n",
      "Best alpha parameter: 0.001\n",
      "Best cross-validation score: 0.5558\n",
      "\n",
      "Performing k-fold cross-validation with best alpha...\n",
      "CV Accuracy: 0.5558 ± 0.0011\n",
      "Individual fold scores: [0.5542775  0.55571531 0.55767695 0.55591948 0.55552005]\n",
      "\n",
      "Training the final model...\n",
      "Model training complete\n",
      "\n",
      "Evaluating model performance on test set...\n",
      "Test Accuracy: 0.6620\n",
      "Confusion Matrix:\n",
      "[[4568    0]\n",
      " [2332    0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80      4568\n",
      "           1       0.00      0.00      0.00      2332\n",
      "\n",
      "    accuracy                           0.66      6900\n",
      "   macro avg       0.33      0.50      0.40      6900\n",
      "weighted avg       0.44      0.66      0.53      6900\n",
      "\n",
      "\n",
      "Analyzing feature importance...\n",
      "Top 10 most important features (by difference in log probability):\n",
      "1. Feature 2: 0.1764\n",
      "2. Feature 4: 0.1077\n",
      "3. Feature 8: 0.0712\n",
      "4. Feature 3: 0.0672\n",
      "5. Feature 19: 0.0576\n",
      "6. Feature 0: 0.0449\n",
      "7. Feature 6: 0.0363\n",
      "8. Feature 47: 0.0302\n",
      "9. Feature 36: 0.0297\n",
      "10. Feature 28: 0.0235\n",
      "\n",
      "Saving results...\n",
      "Results saved to model_results/nb_multinomial_roberta_embedding_results_20250421_191814.json\n",
      "\n",
      "Completed processing roberta_embedding in 7.33 seconds\n",
      "\n",
      "================================================================================\n",
      "EMBEDDING COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Accuracy comparison:\n",
      "tfidf_embedding: Test Accuracy = 0.6620, CV Score = 0.5558\n",
      "bow_embedding: Test Accuracy = 0.6620, CV Score = 0.5558\n",
      "w2v_embedding: Test Accuracy = 0.6083, CV Score = 0.5883\n",
      "roberta_embedding: Test Accuracy = 0.6620, CV Score = 0.5558\n",
      "\n",
      "Comparison results saved to model_results/embedding_comparison_20250421_191814.json\n",
      "\n",
      "Implementation complete!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
